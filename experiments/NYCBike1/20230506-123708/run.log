2023-05-06 12:37:08: Experiment log path in: /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708
2023-05-06 12:37:08: Experiment configs are: Namespace(seed=31, device='cuda', mode='train', best_path='None', debug=False, data_dir='data', dataset='NYCBike1', input_length=19, batch_size=32, test_batch_size=32, graph_file='data/NYCBike1/adj_mx.npz', d_input=2, d_output=2, d_model=64, dropout=0.2, percent=0.1, shm_temp=0.5, nmb_prototype=6, yita=0.6, epochs=100, lr_init=0.001, early_stop=True, early_stop_patience=15, grad_norm=True, max_grad_norm=5, use_dwa=True, temp=4, num_nodes=128, log_dir='/home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708')
2023-05-06 12:38:13: *******Train Epoch 1: averaged Loss : 12.353715
2023-05-06 12:38:14: *******Val Epoch 1: averaged Loss : 9.944051
2023-05-06 12:38:14: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:38:29: *******Train Epoch 2: averaged Loss : 10.116746
2023-05-06 12:38:30: *******Val Epoch 2: averaged Loss : 9.951147
2023-05-06 12:38:45: *******Train Epoch 3: averaged Loss : 9.192625
2023-05-06 12:38:45: *******Val Epoch 3: averaged Loss : 8.460491
2023-05-06 12:38:45: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:39:01: *******Train Epoch 4: averaged Loss : 8.887381
2023-05-06 12:39:01: *******Val Epoch 4: averaged Loss : 8.295358
2023-05-06 12:39:01: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:39:16: *******Train Epoch 5: averaged Loss : 8.718620
2023-05-06 12:39:17: *******Val Epoch 5: averaged Loss : 8.194799
2023-05-06 12:39:17: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:39:32: *******Train Epoch 6: averaged Loss : 8.472925
2023-05-06 12:39:33: *******Val Epoch 6: averaged Loss : 7.901367
2023-05-06 12:39:33: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:39:48: *******Train Epoch 7: averaged Loss : 8.346416
2023-05-06 12:39:48: *******Val Epoch 7: averaged Loss : 7.910743
2023-05-06 12:40:04: *******Train Epoch 8: averaged Loss : 8.248241
2023-05-06 12:40:04: *******Val Epoch 8: averaged Loss : 8.154425
2023-05-06 12:40:20: *******Train Epoch 9: averaged Loss : 8.130153
2023-05-06 12:40:20: *******Val Epoch 9: averaged Loss : 7.830934
2023-05-06 12:40:20: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:40:36: *******Train Epoch 10: averaged Loss : 8.141555
2023-05-06 12:40:36: *******Val Epoch 10: averaged Loss : 7.921416
2023-05-06 12:40:52: *******Train Epoch 11: averaged Loss : 7.994335
2023-05-06 12:40:52: *******Val Epoch 11: averaged Loss : 7.640782
2023-05-06 12:40:52: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:41:08: *******Train Epoch 12: averaged Loss : 7.927462
2023-05-06 12:41:08: *******Val Epoch 12: averaged Loss : 7.566736
2023-05-06 12:41:08: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:41:24: *******Train Epoch 13: averaged Loss : 7.882404
2023-05-06 12:41:24: *******Val Epoch 13: averaged Loss : 7.603353
2023-05-06 12:41:40: *******Train Epoch 14: averaged Loss : 7.813146
2023-05-06 12:41:40: *******Val Epoch 14: averaged Loss : 7.423882
2023-05-06 12:41:40: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:41:56: *******Train Epoch 15: averaged Loss : 7.739275
2023-05-06 12:41:56: *******Val Epoch 15: averaged Loss : 7.369516
2023-05-06 12:41:56: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:42:12: *******Train Epoch 16: averaged Loss : 7.757849
2023-05-06 12:42:12: *******Val Epoch 16: averaged Loss : 7.279443
2023-05-06 12:42:12: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:42:28: *******Train Epoch 17: averaged Loss : 7.638455
2023-05-06 12:42:28: *******Val Epoch 17: averaged Loss : 7.281058
2023-05-06 12:42:44: *******Train Epoch 18: averaged Loss : 7.621543
2023-05-06 12:42:44: *******Val Epoch 18: averaged Loss : 7.438155
2023-05-06 12:43:00: *******Train Epoch 19: averaged Loss : 7.553908
2023-05-06 12:43:00: *******Val Epoch 19: averaged Loss : 7.503226
2023-05-06 12:43:16: *******Train Epoch 20: averaged Loss : 7.549112
2023-05-06 12:43:16: *******Val Epoch 20: averaged Loss : 7.533466
2023-05-06 12:43:32: *******Train Epoch 21: averaged Loss : 7.513941
2023-05-06 12:43:33: *******Val Epoch 21: averaged Loss : 7.268760
2023-05-06 12:43:33: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:43:48: *******Train Epoch 22: averaged Loss : 7.526218
2023-05-06 12:43:49: *******Val Epoch 22: averaged Loss : 7.111488
2023-05-06 12:43:49: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:44:04: *******Train Epoch 23: averaged Loss : 7.458894
2023-05-06 12:44:05: *******Val Epoch 23: averaged Loss : 7.573619
2023-05-06 12:44:20: *******Train Epoch 24: averaged Loss : 7.407915
2023-05-06 12:44:21: *******Val Epoch 24: averaged Loss : 7.154988
2023-05-06 12:44:36: *******Train Epoch 25: averaged Loss : 7.402229
2023-05-06 12:44:37: *******Val Epoch 25: averaged Loss : 7.260696
2023-05-06 12:44:53: *******Train Epoch 26: averaged Loss : 7.401176
2023-05-06 12:44:53: *******Val Epoch 26: averaged Loss : 7.340453
2023-05-06 12:45:09: *******Train Epoch 27: averaged Loss : 7.306102
2023-05-06 12:45:09: *******Val Epoch 27: averaged Loss : 7.020320
2023-05-06 12:45:09: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:45:25: *******Train Epoch 28: averaged Loss : 7.300240
2023-05-06 12:45:25: *******Val Epoch 28: averaged Loss : 7.284728
2023-05-06 12:45:41: *******Train Epoch 29: averaged Loss : 7.299552
2023-05-06 12:45:41: *******Val Epoch 29: averaged Loss : 7.039200
2023-05-06 12:45:57: *******Train Epoch 30: averaged Loss : 7.243961
2023-05-06 12:45:57: *******Val Epoch 30: averaged Loss : 7.255820
2023-05-06 12:46:13: *******Train Epoch 31: averaged Loss : 7.204795
2023-05-06 12:46:13: *******Val Epoch 31: averaged Loss : 6.980986
2023-05-06 12:46:13: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:46:29: *******Train Epoch 32: averaged Loss : 7.185940
2023-05-06 12:46:29: *******Val Epoch 32: averaged Loss : 7.078074
2023-05-06 12:46:45: *******Train Epoch 33: averaged Loss : 7.155641
2023-05-06 12:46:45: *******Val Epoch 33: averaged Loss : 6.928741
2023-05-06 12:46:45: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:47:01: *******Train Epoch 34: averaged Loss : 7.132885
2023-05-06 12:47:01: *******Val Epoch 34: averaged Loss : 6.925112
2023-05-06 12:47:01: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:47:17: *******Train Epoch 35: averaged Loss : 7.093592
2023-05-06 12:47:17: *******Val Epoch 35: averaged Loss : 6.865757
2023-05-06 12:47:17: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:47:33: *******Train Epoch 36: averaged Loss : 7.047432
2023-05-06 12:47:33: *******Val Epoch 36: averaged Loss : 6.847048
2023-05-06 12:47:33: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:47:49: *******Train Epoch 37: averaged Loss : 7.121528
2023-05-06 12:47:50: *******Val Epoch 37: averaged Loss : 6.837726
2023-05-06 12:47:50: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:48:05: *******Train Epoch 38: averaged Loss : 7.072626
2023-05-06 12:48:06: *******Val Epoch 38: averaged Loss : 6.832566
2023-05-06 12:48:06: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:48:21: *******Train Epoch 39: averaged Loss : 6.995894
2023-05-06 12:48:22: *******Val Epoch 39: averaged Loss : 7.042405
2023-05-06 12:48:37: *******Train Epoch 40: averaged Loss : 7.007352
2023-05-06 12:48:38: *******Val Epoch 40: averaged Loss : 6.771305
2023-05-06 12:48:38: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:48:53: *******Train Epoch 41: averaged Loss : 6.968632
2023-05-06 12:48:54: *******Val Epoch 41: averaged Loss : 6.928651
2023-05-06 12:49:09: *******Train Epoch 42: averaged Loss : 6.919415
2023-05-06 12:49:10: *******Val Epoch 42: averaged Loss : 6.833238
2023-05-06 12:49:26: *******Train Epoch 43: averaged Loss : 6.931478
2023-05-06 12:49:26: *******Val Epoch 43: averaged Loss : 6.669797
2023-05-06 12:49:26: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:49:42: *******Train Epoch 44: averaged Loss : 6.903134
2023-05-06 12:49:42: *******Val Epoch 44: averaged Loss : 6.825498
2023-05-06 12:49:58: *******Train Epoch 45: averaged Loss : 6.900926
2023-05-06 12:49:58: *******Val Epoch 45: averaged Loss : 6.797010
2023-05-06 12:50:14: *******Train Epoch 46: averaged Loss : 6.886335
2023-05-06 12:50:14: *******Val Epoch 46: averaged Loss : 7.286704
2023-05-06 12:50:30: *******Train Epoch 47: averaged Loss : 6.834858
2023-05-06 12:50:30: *******Val Epoch 47: averaged Loss : 6.685757
2023-05-06 12:50:46: *******Train Epoch 48: averaged Loss : 6.848804
2023-05-06 12:50:46: *******Val Epoch 48: averaged Loss : 6.651170
2023-05-06 12:50:46: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:51:02: *******Train Epoch 49: averaged Loss : 6.812909
2023-05-06 12:51:02: *******Val Epoch 49: averaged Loss : 6.650280
2023-05-06 12:51:02: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:51:18: *******Train Epoch 50: averaged Loss : 6.815963
2023-05-06 12:51:18: *******Val Epoch 50: averaged Loss : 6.672253
2023-05-06 12:51:34: *******Train Epoch 51: averaged Loss : 6.772405
2023-05-06 12:51:34: *******Val Epoch 51: averaged Loss : 6.694186
2023-05-06 12:51:50: *******Train Epoch 52: averaged Loss : 6.835389
2023-05-06 12:51:50: *******Val Epoch 52: averaged Loss : 6.639040
2023-05-06 12:51:50: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:52:06: *******Train Epoch 53: averaged Loss : 6.808789
2023-05-06 12:52:07: *******Val Epoch 53: averaged Loss : 6.637903
2023-05-06 12:52:07: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:52:22: *******Train Epoch 54: averaged Loss : 6.735915
2023-05-06 12:52:23: *******Val Epoch 54: averaged Loss : 6.693858
2023-05-06 12:52:38: *******Train Epoch 55: averaged Loss : 6.747248
2023-05-06 12:52:39: *******Val Epoch 55: averaged Loss : 6.693018
2023-05-06 12:52:54: *******Train Epoch 56: averaged Loss : 6.706853
2023-05-06 12:52:55: *******Val Epoch 56: averaged Loss : 6.585907
2023-05-06 12:52:55: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:53:10: *******Train Epoch 57: averaged Loss : 6.745172
2023-05-06 12:53:11: *******Val Epoch 57: averaged Loss : 6.575360
2023-05-06 12:53:11: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:53:26: *******Train Epoch 58: averaged Loss : 6.741901
2023-05-06 12:53:27: *******Val Epoch 58: averaged Loss : 6.704839
2023-05-06 12:53:42: *******Train Epoch 59: averaged Loss : 6.707172
2023-05-06 12:53:43: *******Val Epoch 59: averaged Loss : 6.568443
2023-05-06 12:53:43: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:53:59: *******Train Epoch 60: averaged Loss : 6.680447
2023-05-06 12:53:59: *******Val Epoch 60: averaged Loss : 6.518364
2023-05-06 12:53:59: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:54:15: *******Train Epoch 61: averaged Loss : 6.640799
2023-05-06 12:54:15: *******Val Epoch 61: averaged Loss : 6.755094
2023-05-06 12:54:31: *******Train Epoch 62: averaged Loss : 6.650752
2023-05-06 12:54:31: *******Val Epoch 62: averaged Loss : 6.546897
2023-05-06 12:54:47: *******Train Epoch 63: averaged Loss : 6.647782
2023-05-06 12:54:47: *******Val Epoch 63: averaged Loss : 6.601453
2023-05-06 12:55:03: *******Train Epoch 64: averaged Loss : 6.641477
2023-05-06 12:55:03: *******Val Epoch 64: averaged Loss : 6.501701
2023-05-06 12:55:03: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:55:19: *******Train Epoch 65: averaged Loss : 6.664408
2023-05-06 12:55:19: *******Val Epoch 65: averaged Loss : 6.591697
2023-05-06 12:55:35: *******Train Epoch 66: averaged Loss : 6.635447
2023-05-06 12:55:35: *******Val Epoch 66: averaged Loss : 6.650973
2023-05-06 12:55:51: *******Train Epoch 67: averaged Loss : 6.612253
2023-05-06 12:55:51: *******Val Epoch 67: averaged Loss : 6.656127
2023-05-06 12:56:07: *******Train Epoch 68: averaged Loss : 6.602550
2023-05-06 12:56:07: *******Val Epoch 68: averaged Loss : 6.473968
2023-05-06 12:56:07: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:56:23: *******Train Epoch 69: averaged Loss : 6.641927
2023-05-06 12:56:23: *******Val Epoch 69: averaged Loss : 6.557736
2023-05-06 12:56:39: *******Train Epoch 70: averaged Loss : 6.611993
2023-05-06 12:56:40: *******Val Epoch 70: averaged Loss : 6.558895
2023-05-06 12:56:55: *******Train Epoch 71: averaged Loss : 6.580837
2023-05-06 12:56:56: *******Val Epoch 71: averaged Loss : 6.459228
2023-05-06 12:56:56: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:57:11: *******Train Epoch 72: averaged Loss : 6.646135
2023-05-06 12:57:12: *******Val Epoch 72: averaged Loss : 6.473416
2023-05-06 12:57:27: *******Train Epoch 73: averaged Loss : 6.591431
2023-05-06 12:57:28: *******Val Epoch 73: averaged Loss : 6.532849
2023-05-06 12:57:43: *******Train Epoch 74: averaged Loss : 6.566224
2023-05-06 12:57:44: *******Val Epoch 74: averaged Loss : 6.454715
2023-05-06 12:57:44: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 12:57:59: *******Train Epoch 75: averaged Loss : 6.541031
2023-05-06 12:58:00: *******Val Epoch 75: averaged Loss : 6.703493
2023-05-06 12:58:15: *******Train Epoch 76: averaged Loss : 6.543455
2023-05-06 12:58:16: *******Val Epoch 76: averaged Loss : 6.616539
2023-05-06 12:58:32: *******Train Epoch 77: averaged Loss : 6.521120
2023-05-06 12:58:32: *******Val Epoch 77: averaged Loss : 6.491393
2023-05-06 12:58:47: *******Train Epoch 78: averaged Loss : 6.535279
2023-05-06 12:58:48: *******Val Epoch 78: averaged Loss : 6.525273
2023-05-06 12:59:04: *******Train Epoch 79: averaged Loss : 6.517673
2023-05-06 12:59:04: *******Val Epoch 79: averaged Loss : 6.483100
2023-05-06 12:59:20: *******Train Epoch 80: averaged Loss : 6.535789
2023-05-06 12:59:20: *******Val Epoch 80: averaged Loss : 6.511868
2023-05-06 12:59:36: *******Train Epoch 81: averaged Loss : 6.553098
2023-05-06 12:59:36: *******Val Epoch 81: averaged Loss : 6.810144
2023-05-06 12:59:52: *******Train Epoch 82: averaged Loss : 6.559466
2023-05-06 12:59:52: *******Val Epoch 82: averaged Loss : 6.501708
2023-05-06 13:00:08: *******Train Epoch 83: averaged Loss : 6.561234
2023-05-06 13:00:08: *******Val Epoch 83: averaged Loss : 6.565975
2023-05-06 13:00:24: *******Train Epoch 84: averaged Loss : 6.553623
2023-05-06 13:00:24: *******Val Epoch 84: averaged Loss : 6.515661
2023-05-06 13:00:40: *******Train Epoch 85: averaged Loss : 6.493541
2023-05-06 13:00:40: *******Val Epoch 85: averaged Loss : 6.465489
2023-05-06 13:00:56: *******Train Epoch 86: averaged Loss : 6.483878
2023-05-06 13:00:56: *******Val Epoch 86: averaged Loss : 6.513887
2023-05-06 13:01:12: *******Train Epoch 87: averaged Loss : 6.505630
2023-05-06 13:01:12: *******Val Epoch 87: averaged Loss : 6.511429
2023-05-06 13:01:28: *******Train Epoch 88: averaged Loss : 6.483080
2023-05-06 13:01:28: *******Val Epoch 88: averaged Loss : 6.575346
2023-05-06 13:01:44: *******Train Epoch 89: averaged Loss : 6.465904
2023-05-06 13:01:44: *******Val Epoch 89: averaged Loss : 6.443526
2023-05-06 13:01:44: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 13:02:00: *******Train Epoch 90: averaged Loss : 6.427577
2023-05-06 13:02:00: *******Val Epoch 90: averaged Loss : 6.389962
2023-05-06 13:02:00: **************Current best model saved to /home/stud62/ST-SSL/experiments/NYCBike1/20230506-123708/best_model.pth
2023-05-06 13:02:16: *******Train Epoch 91: averaged Loss : 6.492981
2023-05-06 13:02:17: *******Val Epoch 91: averaged Loss : 6.454148
2023-05-06 13:02:32: *******Train Epoch 92: averaged Loss : 6.413956
2023-05-06 13:02:33: *******Val Epoch 92: averaged Loss : 6.616215
2023-05-06 13:02:48: *******Train Epoch 93: averaged Loss : 6.467837
2023-05-06 13:02:49: *******Val Epoch 93: averaged Loss : 6.418086
2023-05-06 13:03:04: *******Train Epoch 94: averaged Loss : 6.429121
2023-05-06 13:03:05: *******Val Epoch 94: averaged Loss : 6.450522
2023-05-06 13:03:20: *******Train Epoch 95: averaged Loss : 6.403658
2023-05-06 13:03:21: *******Val Epoch 95: averaged Loss : 6.517877
2023-05-06 13:03:36: *******Train Epoch 96: averaged Loss : 6.388833
2023-05-06 13:03:37: *******Val Epoch 96: averaged Loss : 6.449284
2023-05-06 13:03:52: *******Train Epoch 97: averaged Loss : 6.437907
2023-05-06 13:03:53: *******Val Epoch 97: averaged Loss : 6.488458
2023-05-06 13:04:09: *******Train Epoch 98: averaged Loss : 6.389753
2023-05-06 13:04:09: *******Val Epoch 98: averaged Loss : 6.552308
2023-05-06 13:04:25: *******Train Epoch 99: averaged Loss : 6.390755
2023-05-06 13:04:25: *******Val Epoch 99: averaged Loss : 6.425399
2023-05-06 13:04:41: *******Train Epoch 100: averaged Loss : 6.377126
2023-05-06 13:04:41: *******Val Epoch 100: averaged Loss : 6.418621
2023-05-06 13:04:41: == Training finished.
Total training time: 27.54 min	best loss: 6.3900	best epoch: 90	
2023-05-06 13:04:41: == Test results.
2023-05-06 13:04:41: INFLOW, MAE: 4.97, MAPE: 24.5765%
2023-05-06 13:04:41: OUTFLOW, MAE: 5.31, MAPE: 24.7446%
