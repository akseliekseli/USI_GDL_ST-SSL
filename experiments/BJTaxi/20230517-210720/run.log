2023-05-17 21:07:20: Experiment log path in: /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720
2023-05-17 21:07:20: Experiment configs are: Namespace(seed=31, device='cuda', mode='train', best_path='None', debug=False, data_dir='data', dataset='BJTaxi', input_length=35, batch_size=20, test_batch_size=20, graph_file='data/BJTaxi/adj_mx.npz', d_input=1, d_output=2, d_model=64, dropout=0.1, percent=0.1, shm_temp=0.5, nmb_prototype=50, yita=0.5, epochs=100, lr_init=0.0005, early_stop=True, early_stop_patience=15, grad_norm=True, max_grad_norm=5, use_dwa=True, temp=2, num_nodes=1024, log_dir='/home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720')
2023-05-17 21:11:29: *******Train Epoch 1: averaged Loss : 33.739927
2023-05-17 21:11:38: *******Val Epoch 1: averaged Loss : 24.388509
2023-05-17 21:11:38: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 21:15:27: *******Train Epoch 2: averaged Loss : 24.001144
2023-05-17 21:15:37: *******Val Epoch 2: averaged Loss : 22.346515
2023-05-17 21:15:37: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 21:19:26: *******Train Epoch 3: averaged Loss : 20.979557
2023-05-17 21:19:35: *******Val Epoch 3: averaged Loss : 19.207080
2023-05-17 21:19:35: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 21:23:23: *******Train Epoch 4: averaged Loss : 21.168525
2023-05-17 21:23:33: *******Val Epoch 4: averaged Loss : 19.841413
2023-05-17 21:27:21: *******Train Epoch 5: averaged Loss : 20.658572
2023-05-17 21:27:30: *******Val Epoch 5: averaged Loss : 20.658966
2023-05-17 21:31:18: *******Train Epoch 6: averaged Loss : 20.160525
2023-05-17 21:31:28: *******Val Epoch 6: averaged Loss : 19.024230
2023-05-17 21:31:28: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 21:35:16: *******Train Epoch 7: averaged Loss : 20.066949
2023-05-17 21:35:25: *******Val Epoch 7: averaged Loss : 18.924891
2023-05-17 21:35:25: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 21:39:14: *******Train Epoch 8: averaged Loss : 19.800142
2023-05-17 21:39:23: *******Val Epoch 8: averaged Loss : 19.207643
2023-05-17 21:43:11: *******Train Epoch 9: averaged Loss : 19.584866
2023-05-17 21:43:21: *******Val Epoch 9: averaged Loss : 19.586224
2023-05-17 21:47:10: *******Train Epoch 10: averaged Loss : 19.410664
2023-05-17 21:47:19: *******Val Epoch 10: averaged Loss : 18.563204
2023-05-17 21:47:19: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 21:51:09: *******Train Epoch 11: averaged Loss : 19.347047
2023-05-17 21:51:18: *******Val Epoch 11: averaged Loss : 18.671319
2023-05-17 21:55:07: *******Train Epoch 12: averaged Loss : 19.121145
2023-05-17 21:55:16: *******Val Epoch 12: averaged Loss : 18.393639
2023-05-17 21:55:16: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 21:59:06: *******Train Epoch 13: averaged Loss : 18.872367
2023-05-17 21:59:15: *******Val Epoch 13: averaged Loss : 18.361853
2023-05-17 21:59:15: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 22:03:05: *******Train Epoch 14: averaged Loss : 18.782964
2023-05-17 22:03:14: *******Val Epoch 14: averaged Loss : 18.770492
2023-05-17 22:07:04: *******Train Epoch 15: averaged Loss : 18.812533
2023-05-17 22:07:13: *******Val Epoch 15: averaged Loss : 18.581383
2023-05-17 22:11:02: *******Train Epoch 16: averaged Loss : 18.745560
2023-05-17 22:11:11: *******Val Epoch 16: averaged Loss : 18.161051
2023-05-17 22:11:11: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 22:15:01: *******Train Epoch 17: averaged Loss : 18.564064
2023-05-17 22:15:10: *******Val Epoch 17: averaged Loss : 18.322109
2023-05-17 22:19:00: *******Train Epoch 18: averaged Loss : 18.461710
2023-05-17 22:19:09: *******Val Epoch 18: averaged Loss : 18.107364
2023-05-17 22:19:09: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 22:22:59: *******Train Epoch 19: averaged Loss : 18.480786
2023-05-17 22:23:08: *******Val Epoch 19: averaged Loss : 18.325580
2023-05-17 22:26:57: *******Train Epoch 20: averaged Loss : 18.329922
2023-05-17 22:27:06: *******Val Epoch 20: averaged Loss : 17.971725
2023-05-17 22:27:06: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 22:30:55: *******Train Epoch 21: averaged Loss : 18.246949
2023-05-17 22:31:05: *******Val Epoch 21: averaged Loss : 17.916923
2023-05-17 22:31:05: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 22:34:54: *******Train Epoch 22: averaged Loss : 18.253364
2023-05-17 22:35:04: *******Val Epoch 22: averaged Loss : 17.940887
2023-05-17 22:38:53: *******Train Epoch 23: averaged Loss : 18.168339
2023-05-17 22:39:02: *******Val Epoch 23: averaged Loss : 17.703791
2023-05-17 22:39:02: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 22:42:51: *******Train Epoch 24: averaged Loss : 18.016509
2023-05-17 22:43:01: *******Val Epoch 24: averaged Loss : 17.986660
2023-05-17 22:46:49: *******Train Epoch 25: averaged Loss : 18.014384
2023-05-17 22:46:59: *******Val Epoch 25: averaged Loss : 17.906611
2023-05-17 22:50:48: *******Train Epoch 26: averaged Loss : 17.950342
2023-05-17 22:50:57: *******Val Epoch 26: averaged Loss : 17.828012
2023-05-17 22:54:46: *******Train Epoch 27: averaged Loss : 17.891298
2023-05-17 22:54:55: *******Val Epoch 27: averaged Loss : 18.243426
2023-05-17 22:58:44: *******Train Epoch 28: averaged Loss : 17.866268
2023-05-17 22:58:53: *******Val Epoch 28: averaged Loss : 17.922897
2023-05-17 23:02:43: *******Train Epoch 29: averaged Loss : 17.841152
2023-05-17 23:02:52: *******Val Epoch 29: averaged Loss : 17.657735
2023-05-17 23:02:52: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 23:06:41: *******Train Epoch 30: averaged Loss : 17.841805
2023-05-17 23:06:50: *******Val Epoch 30: averaged Loss : 17.557170
2023-05-17 23:06:50: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 23:10:40: *******Train Epoch 31: averaged Loss : 17.760381
2023-05-17 23:10:49: *******Val Epoch 31: averaged Loss : 18.630846
2023-05-17 23:14:38: *******Train Epoch 32: averaged Loss : 17.683776
2023-05-17 23:14:48: *******Val Epoch 32: averaged Loss : 17.575998
2023-05-17 23:18:37: *******Train Epoch 33: averaged Loss : 17.614824
2023-05-17 23:18:46: *******Val Epoch 33: averaged Loss : 17.827865
2023-05-17 23:22:36: *******Train Epoch 34: averaged Loss : 17.530079
2023-05-17 23:22:45: *******Val Epoch 34: averaged Loss : 17.296988
2023-05-17 23:22:45: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 23:26:35: *******Train Epoch 35: averaged Loss : 17.568246
2023-05-17 23:26:44: *******Val Epoch 35: averaged Loss : 17.511101
2023-05-17 23:30:33: *******Train Epoch 36: averaged Loss : 17.653206
2023-05-17 23:30:42: *******Val Epoch 36: averaged Loss : 18.126971
2023-05-17 23:34:31: *******Train Epoch 37: averaged Loss : 17.547779
2023-05-17 23:34:41: *******Val Epoch 37: averaged Loss : 17.310993
2023-05-17 23:38:30: *******Train Epoch 38: averaged Loss : 17.521908
2023-05-17 23:38:39: *******Val Epoch 38: averaged Loss : 17.287314
2023-05-17 23:38:39: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 23:42:29: *******Train Epoch 39: averaged Loss : 17.433839
2023-05-17 23:42:38: *******Val Epoch 39: averaged Loss : 17.459479
2023-05-17 23:46:28: *******Train Epoch 40: averaged Loss : 17.514461
2023-05-17 23:46:37: *******Val Epoch 40: averaged Loss : 17.503469
2023-05-17 23:50:26: *******Train Epoch 41: averaged Loss : 17.313671
2023-05-17 23:50:36: *******Val Epoch 41: averaged Loss : 17.285307
2023-05-17 23:50:36: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-17 23:54:26: *******Train Epoch 42: averaged Loss : 17.355948
2023-05-17 23:54:35: *******Val Epoch 42: averaged Loss : 17.482238
2023-05-17 23:58:24: *******Train Epoch 43: averaged Loss : 17.242523
2023-05-17 23:58:34: *******Val Epoch 43: averaged Loss : 17.399758
2023-05-18 00:02:23: *******Train Epoch 44: averaged Loss : 17.285091
2023-05-18 00:02:33: *******Val Epoch 44: averaged Loss : 17.250038
2023-05-18 00:02:33: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210720/best_model.pth
2023-05-18 00:06:22: *******Train Epoch 45: averaged Loss : 17.161481
2023-05-18 00:06:31: *******Val Epoch 45: averaged Loss : 17.443736
