2023-05-17 21:07:14: Experiment log path in: /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714
2023-05-17 21:07:14: Experiment configs are: Namespace(seed=31, device='cuda', mode='train', best_path='None', debug=False, data_dir='data', dataset='BJTaxi', input_length=35, batch_size=20, test_batch_size=20, graph_file='data/BJTaxi/adj_mx.npz', d_input=1, d_output=2, d_model=64, dropout=0.1, percent=0.1, shm_temp=0.5, nmb_prototype=50, yita=0.5, epochs=100, lr_init=0.0005, early_stop=True, early_stop_patience=15, grad_norm=True, max_grad_norm=5, use_dwa=True, temp=2, num_nodes=1024, log_dir='/home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714')
2023-05-17 21:11:26: *******Train Epoch 1: averaged Loss : 33.739927
2023-05-17 21:11:35: *******Val Epoch 1: averaged Loss : 24.388509
2023-05-17 21:11:35: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 21:15:24: *******Train Epoch 2: averaged Loss : 24.001144
2023-05-17 21:15:33: *******Val Epoch 2: averaged Loss : 22.346515
2023-05-17 21:15:33: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 21:19:23: *******Train Epoch 3: averaged Loss : 20.979557
2023-05-17 21:19:32: *******Val Epoch 3: averaged Loss : 19.207080
2023-05-17 21:19:32: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 21:23:21: *******Train Epoch 4: averaged Loss : 21.168525
2023-05-17 21:23:30: *******Val Epoch 4: averaged Loss : 19.841413
2023-05-17 21:27:19: *******Train Epoch 5: averaged Loss : 20.658572
2023-05-17 21:27:28: *******Val Epoch 5: averaged Loss : 20.658966
2023-05-17 21:31:17: *******Train Epoch 6: averaged Loss : 20.160525
2023-05-17 21:31:26: *******Val Epoch 6: averaged Loss : 19.024230
2023-05-17 21:31:26: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 21:35:15: *******Train Epoch 7: averaged Loss : 20.066949
2023-05-17 21:35:24: *******Val Epoch 7: averaged Loss : 18.924891
2023-05-17 21:35:24: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 21:39:13: *******Train Epoch 8: averaged Loss : 19.800142
2023-05-17 21:39:22: *******Val Epoch 8: averaged Loss : 19.207643
2023-05-17 21:43:11: *******Train Epoch 9: averaged Loss : 19.584866
2023-05-17 21:43:20: *******Val Epoch 9: averaged Loss : 19.586224
2023-05-17 21:47:09: *******Train Epoch 10: averaged Loss : 19.410664
2023-05-17 21:47:18: *******Val Epoch 10: averaged Loss : 18.563204
2023-05-17 21:47:18: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 21:51:07: *******Train Epoch 11: averaged Loss : 19.347047
2023-05-17 21:51:17: *******Val Epoch 11: averaged Loss : 18.671319
2023-05-17 21:55:06: *******Train Epoch 12: averaged Loss : 19.121145
2023-05-17 21:55:15: *******Val Epoch 12: averaged Loss : 18.393639
2023-05-17 21:55:15: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 21:59:04: *******Train Epoch 13: averaged Loss : 18.872367
2023-05-17 21:59:13: *******Val Epoch 13: averaged Loss : 18.361853
2023-05-17 21:59:13: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 22:03:02: *******Train Epoch 14: averaged Loss : 18.782964
2023-05-17 22:03:11: *******Val Epoch 14: averaged Loss : 18.770492
2023-05-17 22:07:00: *******Train Epoch 15: averaged Loss : 18.812533
2023-05-17 22:07:09: *******Val Epoch 15: averaged Loss : 18.581383
2023-05-17 22:10:59: *******Train Epoch 16: averaged Loss : 18.745560
2023-05-17 22:11:08: *******Val Epoch 16: averaged Loss : 18.161051
2023-05-17 22:11:08: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 22:14:57: *******Train Epoch 17: averaged Loss : 18.564064
2023-05-17 22:15:06: *******Val Epoch 17: averaged Loss : 18.322109
2023-05-17 22:18:56: *******Train Epoch 18: averaged Loss : 18.461710
2023-05-17 22:19:05: *******Val Epoch 18: averaged Loss : 18.107364
2023-05-17 22:19:05: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 22:22:54: *******Train Epoch 19: averaged Loss : 18.480786
2023-05-17 22:23:03: *******Val Epoch 19: averaged Loss : 18.325580
2023-05-17 22:26:53: *******Train Epoch 20: averaged Loss : 18.329922
2023-05-17 22:27:02: *******Val Epoch 20: averaged Loss : 17.971725
2023-05-17 22:27:02: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 22:30:51: *******Train Epoch 21: averaged Loss : 18.246949
2023-05-17 22:31:00: *******Val Epoch 21: averaged Loss : 17.916923
2023-05-17 22:31:00: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 22:34:50: *******Train Epoch 22: averaged Loss : 18.253364
2023-05-17 22:34:59: *******Val Epoch 22: averaged Loss : 17.940887
2023-05-17 22:38:49: *******Train Epoch 23: averaged Loss : 18.168339
2023-05-17 22:38:58: *******Val Epoch 23: averaged Loss : 17.703791
2023-05-17 22:38:58: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 22:42:48: *******Train Epoch 24: averaged Loss : 18.016509
2023-05-17 22:42:57: *******Val Epoch 24: averaged Loss : 17.986660
2023-05-17 22:46:47: *******Train Epoch 25: averaged Loss : 18.014384
2023-05-17 22:46:56: *******Val Epoch 25: averaged Loss : 17.906611
2023-05-17 22:50:45: *******Train Epoch 26: averaged Loss : 17.950342
2023-05-17 22:50:54: *******Val Epoch 26: averaged Loss : 17.828012
2023-05-17 22:54:43: *******Train Epoch 27: averaged Loss : 17.891298
2023-05-17 22:54:52: *******Val Epoch 27: averaged Loss : 18.243426
2023-05-17 22:58:41: *******Train Epoch 28: averaged Loss : 17.866268
2023-05-17 22:58:50: *******Val Epoch 28: averaged Loss : 17.922897
2023-05-17 23:02:40: *******Train Epoch 29: averaged Loss : 17.841152
2023-05-17 23:02:49: *******Val Epoch 29: averaged Loss : 17.657735
2023-05-17 23:02:49: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 23:06:39: *******Train Epoch 30: averaged Loss : 17.841805
2023-05-17 23:06:48: *******Val Epoch 30: averaged Loss : 17.557170
2023-05-17 23:06:48: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 23:10:38: *******Train Epoch 31: averaged Loss : 17.760381
2023-05-17 23:10:47: *******Val Epoch 31: averaged Loss : 18.630846
2023-05-17 23:14:37: *******Train Epoch 32: averaged Loss : 17.683776
2023-05-17 23:14:46: *******Val Epoch 32: averaged Loss : 17.575998
2023-05-17 23:18:35: *******Train Epoch 33: averaged Loss : 17.614824
2023-05-17 23:18:44: *******Val Epoch 33: averaged Loss : 17.827865
2023-05-17 23:22:33: *******Train Epoch 34: averaged Loss : 17.530079
2023-05-17 23:22:42: *******Val Epoch 34: averaged Loss : 17.296988
2023-05-17 23:22:42: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 23:26:31: *******Train Epoch 35: averaged Loss : 17.568246
2023-05-17 23:26:40: *******Val Epoch 35: averaged Loss : 17.511101
2023-05-17 23:30:29: *******Train Epoch 36: averaged Loss : 17.653206
2023-05-17 23:30:39: *******Val Epoch 36: averaged Loss : 18.126971
2023-05-17 23:34:28: *******Train Epoch 37: averaged Loss : 17.547779
2023-05-17 23:34:37: *******Val Epoch 37: averaged Loss : 17.310993
2023-05-17 23:38:26: *******Train Epoch 38: averaged Loss : 17.521908
2023-05-17 23:38:35: *******Val Epoch 38: averaged Loss : 17.287314
2023-05-17 23:38:35: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 23:42:25: *******Train Epoch 39: averaged Loss : 17.433839
2023-05-17 23:42:34: *******Val Epoch 39: averaged Loss : 17.459479
2023-05-17 23:46:23: *******Train Epoch 40: averaged Loss : 17.514461
2023-05-17 23:46:32: *******Val Epoch 40: averaged Loss : 17.503469
2023-05-17 23:50:21: *******Train Epoch 41: averaged Loss : 17.313671
2023-05-17 23:50:30: *******Val Epoch 41: averaged Loss : 17.285307
2023-05-17 23:50:30: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
2023-05-17 23:54:20: *******Train Epoch 42: averaged Loss : 17.355948
2023-05-17 23:54:29: *******Val Epoch 42: averaged Loss : 17.482238
2023-05-17 23:58:19: *******Train Epoch 43: averaged Loss : 17.242523
2023-05-17 23:58:28: *******Val Epoch 43: averaged Loss : 17.399758
2023-05-18 00:02:18: *******Train Epoch 44: averaged Loss : 17.285091
2023-05-18 00:02:27: *******Val Epoch 44: averaged Loss : 17.250038
2023-05-18 00:02:27: **************Current best model saved to /home/stud62/ST-SSL/experiments/BJTaxi/20230517-210714/best_model.pth
